{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remote: Enumerating objects: 5, done.\u001b[K\n",
      "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
      "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (3/3), done.\n",
      "From https://github.com/sbarham/lv-nlm-he-2019\n",
      "   3be54ef..4567e21  master     -> origin/master\n",
      "Updating 3be54ef..4567e21\n",
      "Fast-forward\n",
      " prepare_data.py | 40 \u001b[32m++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
      " 1 file changed, 40 insertions(+)\n"
     ]
    }
   ],
   "source": [
    "!command git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "!command python prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save directory:\tmodels/brown\n",
      "Save path:\tmodels/brown/brown_aggressive0_constlen_ns1_kls1.00_warm10_0_0_783435.pt\n",
      "using cuda\n",
      "Namespace(aggressive=0, batch_size=32, cuda=True, dataset='brown', dec_dropout_in=0.5, dec_dropout_out=0.5, dec_nh=1024, dec_type='lstm', enc_nh=1024, enc_type='lstm', epochs=100, eval=False, iw_nsamples=500, jobid=0, kl_start=1.0, label=True, load_path='', momentum=0, ni=512, nsamples=1, num_sentences=10, nz=32, sample_every=1, save_dir='models/brown', save_path='models/brown/brown_aggressive0_constlen_ns1_kls1.00_warm10_0_0_783435.pt', seed=783435, taskid=0, test_data='datasets/brown_data/brown.test.txt', test_nepoch=5, train_data='datasets/brown_data/brown.train.txt', val_data='datasets/brown_data/brown.valid.txt', warm_up=10)\n",
      "Train data: 45791 samples\n",
      "finish reading datasets, vocab size is 50484\n",
      "dropped sentences: 0\n",
      "/usr/local/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Beginning training ...\n",
      "-----------------------------------------\n",
      "Epoch 0:\n",
      "epoch: 0, iter: 0, avg_loss: 227.4131, kl: 0.0000, mi: -0.0043, recon: 227.4131, au 0, time elapsed 9.07s\n",
      "epoch: 0, iter: 143, avg_loss: 177.1677, kl: 0.0057, mi: -0.0516, recon: 177.1619, au 0, time elapsed 43.82s\n",
      "epoch: 0, iter: 286, avg_loss: 153.6639, kl: 0.0061, mi: 0.0623, recon: 153.6578, au 0, time elapsed 79.06s\n",
      "epoch: 0, iter: 429, avg_loss: 146.9511, kl: 0.0106, mi: 0.0668, recon: 146.9406, au 0, time elapsed 114.22s\n",
      "epoch: 0, iter: 572, avg_loss: 139.5025, kl: 0.0118, mi: 0.0379, recon: 139.4907, au 0, time elapsed 148.69s\n",
      "epoch: 0, iter: 715, avg_loss: 128.1894, kl: 0.0113, mi: -0.0519, recon: 128.1781, au 0, time elapsed 182.46s\n",
      "epoch: 0, iter: 858, avg_loss: 149.8984, kl: 0.0156, mi: 0.0613, recon: 149.8828, au 0, time elapsed 219.42s\n",
      "epoch: 0, iter: 1001, avg_loss: 135.5640, kl: 0.0159, mi: -0.0702, recon: 135.5481, au 0, time elapsed 254.82s\n",
      "epoch: 0, iter: 1144, avg_loss: 142.4686, kl: 0.0214, mi: -0.0185, recon: 142.4472, au 0, time elapsed 290.75s\n",
      "epoch: 0, iter: 1287, avg_loss: 128.8850, kl: 0.0184, mi: -0.0672, recon: 128.8666, au 0, time elapsed 325.50s\n",
      "epoch: 0, iter: 1430, avg_loss: 126.5228, kl: 0.0183, mi: -0.0690, recon: 126.5045, au 0, time elapsed 359.97s\n",
      "kl weight 1.0000\n",
      "VAL --- avg_loss: 130.8179, kl: 0.0297, mi: -0.0547, recon: 130.7882, nll: 130.8179, ppl: 471.7279\n",
      "0 active units\n",
      "update best loss\n",
      "TEST --- avg_loss: 130.7059, kl: 0.0297, mi: 0.0218, recon: 130.6762, nll: 130.7059, ppl: 462.3947\n",
      "Epoch 1:\n",
      "epoch: 1, iter: 1573, avg_loss: 140.9804, kl: 0.0253, recon: 140.9551,time elapsed 429.77s\n",
      "epoch: 1, iter: 1716, avg_loss: 123.2833, kl: 0.0215, recon: 123.2618,time elapsed 455.85s\n",
      "epoch: 1, iter: 1859, avg_loss: 139.6045, kl: 0.0270, recon: 139.5775,time elapsed 484.54s\n",
      "epoch: 1, iter: 2002, avg_loss: 128.5925, kl: 0.0263, recon: 128.5662,time elapsed 511.39s\n"
     ]
    }
   ],
   "source": [
    "!command python text.py --dataset brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
